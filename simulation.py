"""
Simulation script for AG-inspired quantum error-correcting codes.
(simulation.py)

This module implements a physics-driven noise model tailored to hollow-core
fibers (HCF) carrying both quantum and classical channels (Model 2), includes a
first-order Markov model for temporal correlations, and estimates the
logical block error probability of a CSS code under asymmetric Pauli noise
using Bounded Distance Decoding (BDD).

The model parameters can be adjusted via function arguments. The main entry point,
``run_default_demo``, executes a Monte Carlo simulation for the standard
[[255,33,21]] AG code over a 100 km fiber with 10 dBm co-propagating
classical power.

The algorithm proceeds as follows:

1. Compute the integrated noise generation using the effective length (L_eff) based on fiber attenuation.
2. Compute the mean number of noise photons generated by spontaneous Raman
   scattering (SpRS) and four-wave mixing (FWM). The phase (Z) error
   probability is derived from this. These are the 'baseline' probabilities.
3. Model amplitude (X) errors as a fixed fraction ``eta_px`` (0.3) of the phase
   error probability.
4. Generate correlated error patterns via a two-state Markov process. The hidden
   state persists with probability ``correlation_strength`` (rho=0.6). In the
   low-noise state, the error probability is the baseline rate; in the high-noise
   state, the rate doubles. This implementation results in an effective average
   error rate 1.5x higher than the baseline.
5. Repeat over many Monte Carlo trials; record a block failure if X or Z errors
   exceed the code’s correctable threshold ``t`` (BDD assumption).

To execute the demo, run this file directly with Python 3.
"""

import csv
import math
import random
import time
from pathlib import Path
from typing import Dict, List

# Set a fixed seed for reproducibility of the results reported in the paper.
random.seed(42)

# Conversion factor from dB/km to linear attenuation (1/km, Neperian)
LN10_OVER_10 = math.log(10) / 10.0  # Approx 0.23026

def hcf_noise_model(
    length_km: float,
    classical_power_dBm: float,
    wavelength_separation_nm: float,
    # Coefficients calibrated to match the physical error rates targeted in the study
    # while using a physically correct attenuation model (L_eff).
    raman_coeff: float = 0.0526,
    fwm_coeff: float = 0.717e-4,
    attenuation_db_per_km: float = 0.25,
    eta_px: float = 0.3,
) -> Dict[str, float]:
    """Translate physical parameters into asymmetric Pauli error probabilities.

    This model computes the integrated noise generated by SpRS and FWM based on
    the classical launch power and fiber attenuation, using effective lengths (L_eff).

    Args:
        length_km: Fiber length in kilometers.
        classical_power_dBm: Launch power of the classical channel in dBm.
        wavelength_separation_nm: Spectral separation (in nm).
        raman_coeff: Coefficient for SpRS noise.
        fwm_coeff: Coefficient for FWM noise.
        attenuation_db_per_km: Fiber attenuation in dB per kilometre.
        eta_px: Ratio of amplitude (X) to phase (Z) error probability.

    Returns:
        A dictionary with keys 'p_x' and 'p_z' (baseline probabilities).
    """
    # Convert classical launch power from dBm to Watts
    classical_power_w = 10 ** ((classical_power_dBm - 30) / 10.0)

    # Convert dB/km to linear attenuation coefficient (1/km)
    alpha_lin = attenuation_db_per_km * LN10_OVER_10

    # Calculate effective lengths for linear (SpRS) and quadratic (FWM) processes
    if alpha_lin > 0:
        # L_eff (linear) = (1 - exp(-alpha*L)) / alpha
        L_eff_linear = (1.0 - math.exp(-alpha_lin * length_km)) / alpha_lin
        # L_eff (squared) = (1 - exp(-2*alpha*L)) / (2*alpha)
        L_eff_squared = (1.0 - math.exp(-2 * alpha_lin * length_km)) / (2 * alpha_lin)
    else:
        L_eff_linear = length_km
        L_eff_squared = length_km

    # Integrated power terms
    integrated_power_linear = classical_power_w * L_eff_linear
    integrated_power_squared = (classical_power_w ** 2) * L_eff_squared

    # Mean noise photons from SpRS and FWM processes
    sprs_photons = raman_coeff * integrated_power_linear
    # FWM dependency on wavelength separation is often complex; here modeled simply as proportional.
    fwm_photons = fwm_coeff * integrated_power_squared * wavelength_separation_nm

    # Total mean noise photons
    N_noise = sprs_photons + fwm_photons

    # Phase (Z) error probability: P(noise) = 1 - exp(-N_noise)
    p_z = 1.0 - math.exp(-N_noise)
    # Amplitude (X) error probability assumed to be a fraction of p_z
    p_x = eta_px * p_z
    return {"p_x": p_x, "p_z": p_z}


def markov_correlated_errors(
    p_base: float, correlation_strength: float, n_qubits: int
) -> List[int]:
    """Generate a binary error pattern with first-order Markov correlations.

    Uses a two-state model. State 0 (low noise): P(error) = p_base.
    State 1 (high noise): P(error) = 2 * p_base.
    The state persists with probability `correlation_strength` (rho).
    The transition matrix for the hidden state is symmetric, meaning the
    probability of switching from low-to-high noise is the same as high-to-low.
    This results in a steady-state probability of 0.5 for being in either
    state, leading to an effective average error rate of 1.5 * p_base.

    Args:
        p_base: Baseline error probability (used in the low-noise state).
        correlation_strength: Probability of remaining in the same hidden state (ρ).
        n_qubits: Length of the pattern.

    Returns:
        A list of integers (0 or 1) denoting errors.
    """
    errors = [0] * n_qubits
    state = 0  # 0 for low noise, 1 for high noise

    # Initialize state based on steady state probability (0.5)
    if random.random() < 0.5:
        state = 1

    for i in range(n_qubits):
        # Determine current error probability
        prob = p_base if state == 0 else min(1.0, 2 * p_base)
        errors[i] = 1 if random.random() < prob else 0
        # Update hidden state: stay with probability correlation_strength
        if random.random() > correlation_strength:
            state ^= 1  # flip between 0 and 1
    return errors


def monte_carlo_block_error_asymmetric(
    n: int,
    t: int,
    p_x_base: float,
    p_z_base: float,
    correlation_strength: float,
    trials: int,
) -> Dict[str, float]:
    """Estimate block error probability for asymmetric, correlated errors using BDD.

    A block failure (under Bounded Distance Decoding) is recorded if the number
    of X errors or Z errors exceeds the correctable threshold ``t``. This provides
    an idealized estimate of performance.

    Args:
        n: Block length.
        t: Correctable threshold (floor((d-1)/2)).
        p_x_base: Base amplitude error probability.
        p_z_base: Base phase error probability.
        correlation_strength: Markov correlation parameter (rho).
        trials: Number of Monte Carlo trials.

    Returns:
        A dictionary containing estimated logical failure probabilities (P_L, P_L_X, P_L_Z).
    """
    failures_x = 0
    failures_z = 0
    failures_total = 0
    for _ in range(trials):
        # Generate correlated error patterns for X and Z separately
        x_errors = markov_correlated_errors(p_x_base, correlation_strength, n)
        z_errors = markov_correlated_errors(p_z_base, correlation_strength, n)

        # Bounded Distance Decoding check
        fail_x = sum(x_errors) > t
        fail_z = sum(z_errors) > t

        if fail_x:
            failures_x += 1
        if fail_z:
            failures_z += 1
        if fail_x or fail_z:
            failures_total += 1

    return {
        "P_L": failures_total / float(trials),
        "P_L_X": failures_x / float(trials),
        "P_L_Z": failures_z / float(trials),
    }


def run_default_demo() -> None:
    """Run a demonstration simulation for the [[255,33,21]] AG code."""
    # Code parameters
    n, k, d = 255, 33, 21
    t = (d - 1) // 2
    # Physical parameters (Model 2)
    length_km = 100.0
    classical_power_dBm = 10.0
    wavelength_separation_nm = 5.0
    attenuation_db_per_km = 0.25
    # Simulation parameters
    rho = 0.6  # Correlation strength (ρ)
    trials = 50000  # Number of Monte Carlo trials

    # Compute baseline error probabilities from HCF model
    probs = hcf_noise_model(
        length_km,
        classical_power_dBm,
        wavelength_separation_nm,
        attenuation_db_per_km=attenuation_db_per_km,
    )
    p_x_base, p_z_base = probs["p_x"], probs["p_z"]

    # Calculate effective average error rates due to the Markov model (1.5x increase)
    p_x_eff = 1.5 * p_x_base
    p_z_eff = 1.5 * p_z_base
    # Total effective error rate is the sum of effective X and Z probabilities,
    # approximating the total physical error rate P(X or Z) when P(X)P(Z) is small.
    p_eff = p_x_eff + p_z_eff

    print(
        f"Scenario: L={length_km} km, P_class={classical_power_dBm} dBm, alpha={attenuation_db_per_km} dB/km, ρ={rho}"
    )
    print("HCF Noise Model (Baseline probabilities):")
    print(f"  p_z_base ≈ {p_z_base:.5e}, p_x_base ≈ {p_x_base:.5e}")
    print("Markov Model (Effective average probabilities):")
    print(
        f"  p_z_eff  ≈ {p_z_eff:.5e}, p_x_eff  ≈ {p_x_eff:.5e} (Total effective p_X+p_Z ≈ {p_eff:.4f})"
    )

    # Run Monte Carlo to estimate block error
    print(f"\nRunning Monte Carlo simulation ({trials} trials) with BDD assumption...")
    start = time.time()
    results = monte_carlo_block_error_asymmetric(
        n, t, p_x_base, p_z_base, rho, trials=trials
    )
    runtime = time.time() - start

    p_L = results["P_L"]
    F_e = 1.0 - p_L
    print(f"\n--- Results (seed={42}) ---")
    print(f"Estimated logical block error P_L ≈ {p_L:.3e}")
    print(f"  (P_L_X ≈ {results['P_L_X']:.3e}, P_L_Z ≈ {results['P_L_Z']:.3e})")
    print(f"Estimated entanglement fidelity F_e ≈ {F_e:.4f}")
    print(f"Runtime ≈ {runtime:.2f} s")

    # Write a single-row CSV with key statistics
    # We use a relative path "ag-qec/data" to ensure compatibility with the
    # LaTeX compilation environment, which expects the data in this subdirectory.
    # If running standalone, ensure this path exists relative to the script location.
    script_dir = Path(__file__).resolve().parent
    out_dir = script_dir / "ag-qec" / "data"
    out_dir.mkdir(parents=True, exist_ok=True)
    out_file = out_dir / "ag_qec_results.csv"
    with out_file.open("w", newline="") as f:
        writer = csv.writer(f)
        writer.writerow(
            [
                "length_km",
                "classical_power_dBm",
                "p_z_base",
                "p_x_base",
                "p_z_eff",
                "p_x_eff",
                "p_eff",
                "P_L",
                "F_e",
                "runtime_sec",
            ]
        )
        writer.writerow(
            [
                length_km,
                classical_power_dBm,
                p_z_base,
                p_x_base,
                p_z_eff,
                p_x_eff,
                p_eff,
                p_L,
                F_e,
                runtime,
            ]
        )
    print(f"Wrote {out_file}")


if __name__ == "__main__":
    run_default_demo()
